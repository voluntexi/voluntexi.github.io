<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>RAG 解析 | 威伦特</title>
<link rel="shortcut icon" href="https://voluntexi.github.io//favicon.ico?v=1769005591865">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://voluntexi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="RAG 解析 | 威伦特 - Atom Feed" href="https://voluntexi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术的方法，旨在提升大模型输出的稳定性，减少幻觉现象

概述
RAG（Retrieval-Augmented Generation，检索增..." />
    <meta name="keywords" content="大模型" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://voluntexi.github.io/">
  <img class="avatar" src="https://voluntexi.github.io//images/avatar.png?v=1769005591865" alt="">
  </a>
  <h1 class="site-title">
    威伦特
  </h1>
  <p class="site-description">
    解码生命
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              RAG 解析
            </h2>
            <div class="post-info">
              <span>
                2025-11-08
              </span>
              <span>
                21 min read
              </span>
              
                <a href="https://voluntexi.github.io/da-mo-xing/" class="post-tag">
                  # 大模型
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://img1.baidu.com/it/u=1529662668,992752961&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=889&amp;h=500" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术的方法，旨在提升大模型输出的稳定性，减少幻觉现象</p>
<!-- more -->
<h2 id="概述">概述</h2>
<p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术的方法，旨在提升大模型输出的稳定性，减少幻觉现象。同时，它打破了传统领域模型需要微调的限制，通过将领域语料直接作为 prompt 输入，即可实现领域大模型的效果。</p>
<p>该技术最早由 Facebook 团队于 2020 年提出，并在 2024 年得到广泛应用，成为当年最具实用价值的技术之一。进入 2025 年，随着 Agent 元年的到来，RAG 与 Agent 的结合催生了 Agentic RAG，成为当前最具代表性的应用范式之一。</p>
<p>而本文则将从传统的 RAG 出发，逐步进入到 Agentic RAG~</p>
<h2 id="rag-传统rag">RAG (传统RAG)</h2>
<p>如 RAG 的英文全称所示，传统 RAG 的核心流程分为三步：检索、增强和生成。生成阶段将检索到的信息作为上下文输入大模型，从而生成答案。因此，构建一个高效的 RAG 系统，关键在于解决两个问题：</p>
<ul>
<li>
<p>怎么让大模型检索到更有用的知识？</p>
</li>
<li>
<p>怎么让模型更好的利用知识生成回复？</p>
</li>
</ul>
<p>RAG 系统的整体架构如下图所示：<img src="https://cfcdn.yuanchaofa.com/blog/2025/20251003193522.png" alt="image.png" loading="lazy"></p>
<h3 id="怎么让大模型检索到更有用的知识">怎么让大模型检索到更有用的知识？</h3>
<p>解决这一问题的第一步是知识入库，即将文档预处理并存储到<strong>向量数据库</strong>中。</p>
<blockquote>
<p>向量数据库是一种专门设计用于存储、索引和管理<strong>高维向量</strong>数据的数据库。而高维向量是由嵌入模型将非结构化数据（文本、图像、音频等）转换为高维数值表示，用于捕捉数据的语义或特征。</p>
<p>与传统关系型数据库或键值数据库不同，向量数据库的核心优势在于<strong>相似性搜索</strong>，即通过计算向量间的距离（通常为余弦相似度），快速找到与查询最相似的向量集合。</p>
</blockquote>
<p>预处理过程主要包括：文档加载、文本切分、向量化存储。</p>
<p><strong>环境准备：</strong></p>
<pre><code class="language-toml">requires-python = &quot;&gt;=3.12&quot;
dependencies = [
    &quot;langchain&gt;=0.3.27&quot;,
    &quot;langchain-chroma&gt;=0.2.6&quot;,
    &quot;langchain-community&gt;=0.3.30&quot;,
    &quot;langchain-deepseek&gt;=0.1.4&quot;,
    &quot;langchain-openai&gt;=0.3.34&quot;,
    &quot;langgraph&gt;=0.6.8&quot;,
]
</code></pre>
<ol>
<li>
<p>首先导入库：</p>
<pre><code class="language-python">from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_openai import OpenAI
from langchain_core.prompts import PromptTempl
</code></pre>
</li>
<li>
<p>加载知识文档</p>
<p>在当前目录下创建一个&quot;knowledge_base.txt&quot;文件，然后写入文档内容，我们假设文档里的内容就是我们收集的大量知识数据。</p>
<pre><code class="language-python">loader = TextLoader(&quot;knowledge_base.txt&quot;)
documents = loader.load()
</code></pre>
</li>
<li>
<p>将文档中的文本进行切分</p>
<pre><code class="language-python">text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # 每个文本块的大小
    chunk_overlap=50,  # 文本块之间的重叠部分
)
splits = text_splitter.split_documents(documents)
</code></pre>
</li>
<li>
<p>向量化存储</p>
<pre><code class="language-python">embeddings = OpenAIEmbeddings(
    base_url=&quot;https://api.siliconflow.cn/v1&quot;,
    model=&quot;Qwen/Qwen3-Embedding-0.6B&quot;,
    api_key=&quot;your api_key&quot;,
)
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory=&quot;./chroma_db&quot;,  # 持久化存储路径
)
</code></pre>
</li>
</ol>
<p>这里使用的<strong>硅基流动</strong>提供的API，可以<a href="https://cloud.siliconflow.cn/me/account/ak">通过这里</a> 获取</p>
<ol start="5">
<li>
<p>加载向量数据库，获取相关的文档片段</p>
<pre><code class="language-python">embedding = OpenAIEmbeddings(
    base_url=&quot;https://api.siliconflow.cn/v1&quot;,
    model=&quot;Qwen/Qwen3-Embedding-0.6B&quot;,
    api_key=&quot;your api_key&quot;,
)

vectorstore = Chroma(
    collection_name=&quot;knowledge_base&quot;,
    persist_directory=&quot;./chroma_db&quot;,
    embedding_function=embedding,
)

query = &quot;什么是Agentic RAG？和普通的RAG有什么区别？&quot; #假设你的问题
docs = vectorstore.similarity_search(query, k=3)
</code></pre>
<p>返回的 docs 就是检索到的相关的3条文档，至此我们解决了第一个问题。</p>
</li>
</ol>
<h3 id="怎么让模型更好的利用知识生成回复">怎么让模型更好的利用知识生成回复？</h3>
<p>在获取相关文档片段后，关键在于如何设计提示词，使大模型能够有效利用这些信息生成高质量回答。</p>
<ol>
<li>
<p>拼接检索到的文档</p>
<pre><code class="language-python">docs = vectorstore.similarity_search(query, k=3)
content = &quot;\n\n&quot;.join(
    f&quot;第{i+1}篇参考文档：{d.page_content}&quot; for i, d in enumerate(docs)
)
</code></pre>
</li>
<li>
<p>构建提示词</p>
<pre><code class="language-python">prompt_template = &quot;&quot;&quot;
    你是一个专业的问答助手，请根据以下参考文档回答用户的问题。
    如果参考文档中没有相关信息，请诚实地说不知道，不要编造答案。
    你的回答只需要包含最终答案，不需要包含参考文档内容。
    你的回答需要保持专业且简洁，回答不要重复。
    参考文档：
    {context}

    用户问题：{question}

    回答：
&quot;&quot;&quot;
prompt = PromptTemplate(
    template=prompt_template,
    input_variables=[&quot;context&quot;, &quot;question&quot;],
)     
</code></pre>
</li>
<li>
<p>构建大模型并生成回答</p>
<pre><code class="language-python">llm = OpenAI(
    model=&quot;THUDM/glm-4-9b-chat&quot;,
    temperature=0,
    max_retries=3,
    base_url=&quot;https://api.siliconflow.cn/v1&quot;,
    api_key=&quot;your api_key&quot;,
)

final_prompt = prompt.format(context=context, question=query)

print(f&quot;最终的 Prompt 内容：{final_prompt}&quot;)
response = llm.predict(final_prompt)

print(f&quot;问题: {query}&quot;)
print(f&quot;回答: {response}&quot;)
print(f&quot;\n参考文档数量: {len(docs)}&quot;)
</code></pre>
</li>
</ol>
<p>至此，传统 RAG 的完整流程已构建完成。</p>
<blockquote>
<p>这里代码仅仅起到的实例作用，在实际的需求中，每一步骤都可能涉及到大量的难点和问题。</p>
</blockquote>
<h2 id="agentic-rag">Agentic RAG</h2>
<p>Agentic RAG 并非通过增加系统复杂度来提升性能，而是<strong>让模型具备自主决策能力</strong>。与传统 RAG 一次性将文档塞入 Prompt 不同，Agentic RAG 让大模型扮演“决策者”角色：<strong>先制定策略，再调用工具逐步收集证据，最后基于证据作答并引用来源</strong>。只要在传统 RAG 的三步流程中加入大模型的自主决策过程，即可称之为 Agentic RAG。</p>
<p>流程如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251007132359.png" alt="image.png|700x264" loading="lazy"></figure>
<ul>
<li>让大模型作为“智能体（Agent）”充当控制器，结合一组工具（检索、查看元数据、读取片段等）执行“思考→行动→观察”的循环（Reason–Act–Observe）。</li>
<li>在回答之前，按需多轮调用工具，逐步从“找到相关文件”走到“读取关键片段”，最后基于被读取的证据组织答案，并给出引用</li>
</ul>
<h3 id="agentic-rag-样例">Agentic RAG 样例</h3>
<p>样例 1： 场景：用户问“LangChain 框架的函数调用功能怎么实现？”，而知识库文档使用的是“Function Calling/Tool Calling”等英文术语，导致首次中文检索相关度很低。</p>
<pre><code>用户查询: “LangChain 框架的函数调用功能怎么实现？”
向量检索: 基于“LangChain”“函数调用”做相似度搜索
检索结果: 返回3个chunk，但都不够相关（最高分 0.65）
生成结果: “抱歉，未找到关于 LangChain 函数调用功能的具体信息...”
</code></pre>
<p>Agentic RAG 的表现（每一轮都是 LLM 根据检索反馈自动调整关键词与表达）：</p>
<pre><code>第1轮搜索：
- 工具：query_knowledge_base(&quot;LangChain 函数调用 功能 实现&quot;)
- 观察：命中低、证据不足
- 决策：尝试改写查询词

第2轮搜索（术语同义转换）：
- 推理：“函数调用”常见英文术语为 “Function Calling”
- 工具：query_knowledge_base(&quot;LangChain Function Calling&quot;)
- 观察：命中高相关chunk（相似度 0.89），含实现细节

第3轮搜索（可选补充）：
- 工具：query_knowledge_base(&quot;LangChain Tool Calling&quot;)
- 观察：补充工具使用相关文档


回答：
- 基于已读取片段整理实现步骤，包含“函数调用”的最小实现片段与说明。
</code></pre>
<p>样例 2：这里只描述 Agentic RAG 的表现，不展示具体实现。 场景：用户提问“LangChain 框架的函数调用功能怎么实现？”，但是由于策略问题可能导致分块很细，导致检索的内容不完整。</p>
<pre><code>Agentic RAG 的表现：
第1轮搜索：
- 工具：query_knowledge_base(&quot;LangChain 函数调用 功能 实现&quot;)
- 观察：命中 chunk 8 （这个 Chunk 可能不完整）
- 决策：chunk8 包含了函数调用的实现细节，但是上下文有些不完整，所以我需要读取 chunk8 前后两个 chunk 来补充上下文。

第2轮搜索（补充上下文）：
- 工具：read_file_chunks([{&quot;fileId&quot;: 42, &quot;chunkIndex&quot;: 7}, {&quot;fileId&quot;: 42, &quot;chunkIndex&quot;: 9}])
- 观察：读取到 chunk 7 与 chunk 7，包含了完整的函数调用实现细节。
- 决策：基于 chunk 7/8/9 中的信息，进行回复。

回答：
- 基于 chunk 7/8/9 中的信息，整理实现步骤，包含“函数调用”的最小实现片段与说明。
</code></pre>
<h3 id="代码示例">代码示例</h3>
<p>一个典型的 Agentic RAG 例子：先粗后细 → 先找候选文件片段→ 看文件元信息→ 精读片段→ 基于所读片段组织答案并给出引用。</p>
<ol>
<li>
<p>首先导入库</p>
<pre><code class="language-python">from langchain.tools import tool
from langchain.agents import create_agent
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
import json
</code></pre>
</li>
<li>
<p>构建给大模型使用的工具 tools，其中存储数据的管理类<code>MokeKnowledgeBaseController</code>的实现位于本节末尾</p>
<pre><code class="language-python">kb_controller = MokeKnowledgeBaseController()  
knowledge_base_id = 1

@tool(
   &quot;query_knowledge_base&quot;,
   description=&quot;在知识库中搜索相关内容，输入是查询字符串，返回相关的文件块信息&quot;,
)
def query_knowledge_base(query: str) -&gt; any:
   results = kb_controller.search(knowledge_base_id, query)
   return json.dumps(results, ensure_ascii=False, indent=2)

@tool(
   &quot;get_files_meta&quot;,
   description=&quot;获取文件的元信息，输入是文件id列表，返回文件的基本信息&quot;,
)
def get_files_meta(fileIds: list[int]) -&gt; any:
   if not fileIds:
       return &quot;请提供文件id&quot;
   results = kb_controller.getFileMeta(knowledge_base_id, fileIds)
   return json.dumps(results, ensure_ascii=False, indent=2)

@tool(
   &quot;read_file_chunks&quot;,
   description=&quot;读取指定的文件块内容，输入是文件块信息列表，返回对应的内容&quot;,
)
def read_files_chunks(chunks: list[dict[str, int]]) -&gt; any:
   if not chunks:
       return &quot;请提供文件块信息&quot;
   results = kb_controller.readFileChunk(knowledge_base_id, chunks)
   return results

@tool(
   &quot;list_files&quot;,
   description=&quot;分页列出知识库中的文件，输入是页码和每页大小，返回文件列表&quot;,
)
def list_files(page: int, page_size: int) -&gt; any:
   results = kb_controller.listFilesPaginated(knowledge_base_id, page, page_size)
   return json.dumps(results, ensure_ascii=False, indent=2)

tools = [query_knowledge_base, get_files_meta, read_files_chunks, list_files]
</code></pre>
</li>
<li>
<p>构建提示词</p>
</li>
</ol>
<pre><code class="language-python">SYSTEM_PROMPT = &quot;&quot;&quot;
你是一个Agentic RAG 助手。请遵循：
- 先用 query_knowledge_base 搜索；必要时使用 get_files_meta 查看文件信息，或用 list_files 浏览备选。
- 最终必须用 read_file_chunks 读取少量最相关的片段，再基于片段内容作答。
- 不要编造；若证据不足请说明不足并建议下一步。
- 回答末尾用“引用：”列出你实际读取过的 fileId 和 chunkIndex（或文件名）。
&quot;&quot;&quot;
</code></pre>
<ol start="4">
<li>
<p>构建大模型并生成回答</p>
<pre><code class="language-python">llm = ChatOpenAI(
   model=&quot;THUDM/glm-4-9b-chat&quot;,
   temperature=0,
   max_retries=3,
   base_url=&quot;https://api.siliconflow.cn/v1&quot;,
   api_key=&quot;sk-ugiijxjibvmqqropkuepubdcvnakdrnafjnrwlgwbqqclgwd&quot;,
)
agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)

question = &quot;请基于知识库，概述RAG的优缺点，并给出引用&quot;

result = agent.invoke({&quot;messages&quot;: [(&quot;user&quot;, question)]})

final_answer = result[&quot;messages&quot;][-1].content
print(final_answer)
</code></pre>
</li>
</ol>
<p>输出</p>
<pre><code>RAG（Retrieval-Augmented Generation）是一种结合检索和生成的技术，通过从外部知识源检索相关信息来增强大语言模型的生成能力。其优点包括能够访问最新信息、减少模型
幻觉、提供可追溯的信息来源，以及无需重新训练模型即可更新知识。然而，RAG也存在一些缺点，如检索质量直接影响生成效果、增加了系统复杂度、对向量数据库的依赖，以及
可能存在检索延迟。此外，传统RAG系统通常采用固定的检索-生成流程，无法根据问题复杂度动态调整策略。Agentic RAG通过引入智能体，使系统能够自主决策何时检索、如何检
索以及检索多少内容，从而提升复杂问题的处理能力。

引用：
- 优点：rag_introduction.md, chunk_index: 1
- 缺点：rag_introduction.md, chunk_index: 2
- 传统RAG限制：rag_introduction.md, chunk_index: 3
- Agentic RAG：rag_introduction.md, chunk_index: 4
</code></pre>
<p><strong>MokeKnowledgeBaseController 类的实现</strong></p>
<pre><code class="language-python">@dataclass
class FileChunk:
    file_id: int
    chunk_index: int
    content: str


@dataclass
class FileInfo:
    id: int
    filename: str
    chunk_count: int
    status: str = &quot;done&quot;


class MokeKnowledgeBaseController:

    def __init__(self):
        self.files = [
            FileInfo(1, &quot;rag_introduction.md&quot;, 5),
            FileInfo(2, &quot;llm_fundamentals.md&quot;, 4),
            FileInfo(3, &quot;vector_search.md&quot;, 3),
            FileInfo(4, &quot;prompt_engineering.md&quot;, 4),
        ]

        self.chunks = {
            (1, 0): FileChunk(
                1,
                0,
                &quot;RAG (Retrieval-Augmented Generation) 是一种结合检索和生成的技术，通过从外部知识源检索相关信息来增强大语言模型的生成能力。&quot;,
            ),
            (1, 1): FileChunk(
                1,
                1,
                &quot;RAG 的优点包括：1) 能够访问最新信息，2) 减少模型幻觉，3) 提供可追溯的信息来源，4) 无需重新训练模型即可更新知识。&quot;,
            ),
            (1, 2): FileChunk(
                1,
                2,
                &quot;RAG 的缺点包括：1) 检索质量直接影响生成效果，2) 增加了系统复杂度，3) 对向量数据库的依赖，4) 可能存在检索延迟。&quot;,
            ),
            (1, 3): FileChunk(
                1,
                3,
                &quot;传统 RAG 系统通常采用固定的检索-生成流程，无法根据问题复杂度动态调整策略。&quot;,
            ),
            (1, 4): FileChunk(
                1,
                4,
                &quot;Agentic RAG 通过引入智能体，使系统能够自主决策何时检索、如何检索以及检索多少内容，从而提升复杂问题的处理能力。&quot;,
            ),
            (2, 0): FileChunk(
                2,
                0,
                &quot;大语言模型 (LLM) 是基于 Transformer 架构的深度学习模型，通过预训练学习语言的统计规律。&quot;,
            ),
            (2, 1): FileChunk(
                2, 1, &quot;LLM 的核心能力包括自然语言理解、生成、推理和少样本学习等。&quot;
            ),
            (2, 2): FileChunk(
                2, 2, &quot;LLM 的局限性包括知识截止时间、可能产生幻觉、计算资源消耗大等。&quot;
            ),
            (2, 3): FileChunk(
                2,
                3,
                &quot;工具调用是 LLM 的重要扩展能力，使模型能够与外部系统交互，执行复杂任务。&quot;,
            ),
            (3, 0): FileChunk(
                3,
                0,
                &quot;向量搜索是 RAG 系统的核心组件，通过将文本转换为向量表示来实现语义相似度匹配。&quot;,
            ),
            (3, 1): FileChunk(
                3,
                1,
                &quot;常见的向量搜索算法包括 FAISS、Chroma、Pinecone 等，各有不同的性能特点。&quot;,
            ),
            (3, 2): FileChunk(
                3,
                2,
                &quot;向量搜索的效果很大程度上依赖于embedding模型的质量和索引构建策略。&quot;,
            ),
            (4, 0): FileChunk(
                4,
                0,
                &quot;提示工程是优化大模型表现的重要技术，包括设计有效的提示模板、上下文管理等。&quot;,
            ),
            (4, 1): FileChunk(
                4, 1, &quot;良好的提示设计原则包括：清晰明确、提供示例、结构化输出格式等。&quot;
            ),
            (4, 2): FileChunk(
                4, 2, &quot;Agent 系统的提示设计需要考虑工具调用的策略指导和错误处理机制。&quot;
            ),
            (4, 3): FileChunk(
                4, 3, &quot;系统提示词应该明确定义 Agent 的角色、能力边界和行为规范。&quot;
            ),
        }

    def search(self, kb_id: int, query: str) -&gt; list[dict]:
        # 模拟语义搜索
        query_lower = query.lower()
        results = []
        keywords = [
            &quot;rag&quot;,
            &quot;agentic&quot;,
            &quot;优缺点&quot;,
            &quot;优点&quot;,
            &quot;缺点&quot;,
            &quot;llm&quot;,
            &quot;检索&quot;,
            &quot;生成&quot;,
            &quot;向量&quot;,
            &quot;搜索&quot;,
        ]
        for (file_id, chunk_index), chunk in self.chunks.items():
            content_lower = chunk.content.lower()
            score = 0
            for keyword in keywords:
                if keyword in query_lower and keyword in content_lower:
                    score += 1
            if score &gt; 0 or any(word in content_lower for word in query_lower.split()):
                file_info = next((f for f in self.files if f.id == file_id), None)
                results.append(
                    {
                        &quot;file_id&quot;: file_id,
                        &quot;chunk_index&quot;: chunk_index,
                        &quot;filename&quot;: file_info.filename,
                        &quot;score&quot;: score + 0.5,
                        &quot;preview&quot;: (
                            chunk.content[:100] + &quot;...&quot;
                            if len(chunk.content) &gt; 100
                            else chunk.content
                        ),
                    }
                )
        results.sort(key=lambda x: x[&quot;score&quot;], reverse=True)
        return results[:5]

    def getFileMeta(self, kb_id: int, file_ids: list[int]) -&gt; list[dict]:
        &quot;&quot;&quot;获取文件元信息&quot;&quot;&quot;
        result = []
        for file_id in file_ids:
            file_info = next((f for f in self.files if f.id == file_id), None)
            if file_info:
                result.append(
                    {
                        &quot;file_id&quot;: file_info.id,
                        &quot;filename&quot;: file_info.filename,
                        &quot;chunk_count&quot;: file_info.chunk_count,
                        &quot;status&quot;: file_info.status,
                    }
                )
        return result

    def readFileChunk(self, kb_id: int, chunks: list[dict[str, int]]) -&gt; list[dict]:
        result = []
        for chunk_spec in chunks:
            file_id = chunk_spec[&quot;file_id&quot;]
            chunk_index = chunk_spec[&quot;chunk_index&quot;]
            chunk = self.chunks.get((file_id, chunk_index), None)
            if chunk:
                result.append(
                    {
                        &quot;file_id&quot;: file_id,
                        &quot;chunk_index&quot;: chunk_index,
                        &quot;content&quot;: chunk.content,
                        &quot;filename&quot;: next(
                            (f.filename for f in self.files if f.id == file_id), &quot;&quot;
                        ),
                    }
                )
        return result

    def listFilesPaginated(self, kb_id: int, page: int, page_size: int) -&gt; dict:
        total_files = len(self.files)
        start_index = (page - 1) * page_size
        end_index = start_index + page_size
        paginated_files = self.files[start_index:end_index]
        return {
            &quot;total&quot;: total_files,
            &quot;page&quot;: page,
            &quot;page_size&quot;: page_size,
            &quot;files&quot;: [
                {
                    &quot;file_id&quot;: f.id,
                    &quot;filename&quot;: f.filename,
                    &quot;chunk_count&quot;: f.chunk_count,
                    &quot;status&quot;: f.status,
                }
                for f in paginated_files
            ],
        }
</code></pre>
<h3 id="基于强化学习的-agentic-rag">基于强化学习的 Agentic RAG</h3>
<p>为进一步提升 Agent 的检索与推理能力，研究者引入强化学习（RL），让模型自主学会更优的“检索-取证”策略，而非依赖人工设计的提示词和规则。前面介绍的基于提示词的 Agentic RAG 虽然有效，但仍然存在一些局限性：</p>
<ol>
<li>依赖人工设计的提示词和规则，难以适应复杂多变的场景</li>
<li>缺乏对搜索行为的系统性优化，无法从经验中学习和改进</li>
<li>难以处理多轮交互式搜索的复杂决策过程</li>
</ol>
<p>自 OpenAI-DeepResearch 以及 DeepSeek-R1 发布之后，使用强化学习（RL）来增强模型能力已经是一个常见的做法，其中一个复现 DeepSearch 的代表性工作是 <a href="https://arxiv.org/pdf/2503.09516">Search-R1</a>，它通过 RL 训练 LLM 学会在推理过程中自主生成搜索查询并利用实时检索结果。</p>
<figure data-type="image" tabindex="2"><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251003193047.png" alt="image.png" loading="lazy"></figure>
<h4 id="最小实现示例">最小实现示例</h4>
<pre><code class="language-python">import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from torch.optim import Adam

model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen2.5-7B&quot;)
tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen2.5-7B&quot;)

class SearchEngine:
    def search(self, query):
        # 实现搜索逻辑，返回搜索结果
        # 可以是本地检索器或在线搜索引擎
        pass

def generate_trajectory(model, tokenizer, question, search_engine):
    trajectory = []
    actions = []
    log_probs = []
    state = question
    done = False

    while not done:
        # 模型推理
        inputs = tokenizer(state, return_tensors=&quot;pt&quot;)
        outputs = model.generate(**inputs, max_new_tokens=100, output_scores=True, return_dict_in_generate=True)

        # 获取输出文本和概率
        step_output = tokenizer.decode(outputs.sequences[0])
        action_prob = torch.softmax(outputs.scores[-1], dim=-1).max().item()  # 简化处理

        trajectory.append(step_output)

        # 检查是否需要搜索
        if &quot;&lt;search&gt;&quot; in step_output:
            # 记录搜索动作和概率
            actions.append(&quot;search&quot;)
            log_probs.append(action_prob)

            # 提取搜索查询
            query = extract_search_query(step_output)

            # 执行搜索
            search_results = search_engine.search(query)

            # 更新状态
            state = state + step_output + search_results
        else:
            # 记录生成答案动作和概率
            actions.append(&quot;answer&quot;)
            log_probs.append(action_prob)

            # 生成最终答案
            done = True

    return trajectory, actions, torch.tensor(log_probs)

# 定义 RL 训练函数
def train_rl(model, dataset, search_engine, epochs=3, lr=1e-5):
    optimizer = Adam(model.parameters(), lr=lr)

    for epoch in range(epochs):
        for question, answer in dataset:
            # 生成包含搜索操作的轨迹
            with torch.no_grad():
                trajectory, actions, log_probs = generate_trajectory(
                    model, tokenizer, question, search_engine
                )

            # 计算奖励
            final_answer = trajectory[-1]
            reward = compute_reward(final_answer, answer)

            # 计算策略梯度损失
            policy_loss = -torch.mean(log_probs * reward)

            # 更新模型
            optimizer.zero_grad()
            policy_loss.backward()
            optimizer.step()

    return model

# 辅助函数：提取搜索查询
def extract_search_query(text):
    # 从文本中提取搜索查询
    # 假设查询格式为 &lt;search&gt;查询内容&lt;/search&gt;
    start_tag = &quot;&lt;search&gt;&quot;
    end_tag = &quot;&lt;/search&gt;&quot;
    start_idx = text.find(start_tag) + len(start_tag)
    end_idx = text.find(end_tag)

    if start_idx &gt;= len(start_tag) and end_idx &gt; start_idx:
        return text[start_idx:end_idx].strip()
    return &quot;&quot;

# 辅助函数：计算奖励
def compute_reward(prediction, ground_truth):

    if prediction == ground_truth:
        return 1.0
    return 0.0
</code></pre>
<h2 id="总结">总结</h2>
<table>
<thead>
<tr>
<th>特点</th>
<th>传统RAG</th>
<th>Agentic RAG</th>
</tr>
</thead>
<tbody>
<tr>
<td>决策</td>
<td>被动，仅仅依靠固定的流程</td>
<td>主动，能够根据内容自主决策如何采取行动</td>
</tr>
<tr>
<td>数据获取</td>
<td>按照既定规则从固定的数据源检索</td>
<td>可以从多个外部源中动态的检索</td>
</tr>
<tr>
<td>适配度</td>
<td>适配度低，不同的输入效果不同</td>
<td>能够不断完善提高性能</td>
</tr>
<tr>
<td>自主性</td>
<td>依赖用户查询</td>
<td>独立运作，实时学习</td>
</tr>
<tr>
<td>用例</td>
<td>常见问题的解答和静态搜索</td>
<td>聊天机器人、推荐系统和复杂的工作流程</td>
</tr>
</tbody>
</table>
<h2 id="参考文章">参考文章</h2>
<p>[1] <a href="https://yuanchaofa.com/post/from-native-rag-to-agentic-rag.html">RAG 进化之路：传统 RAG 到工具与强化学习双轮驱动的 Agentic RAG | chaofa用代码打点酱油</a></p>
<p>[2] <a href="https://www.geeksforgeeks.org/artificial-intelligence/what-is-agentic-rag/">What is Agentic RAG? - GeeksforGeeks</a></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#rag-%E4%BC%A0%E7%BB%9Frag">RAG (传统RAG)</a>
<ul>
<li><a href="#%E6%80%8E%E4%B9%88%E8%AE%A9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A3%80%E7%B4%A2%E5%88%B0%E6%9B%B4%E6%9C%89%E7%94%A8%E7%9A%84%E7%9F%A5%E8%AF%86">怎么让大模型检索到更有用的知识？</a></li>
<li><a href="#%E6%80%8E%E4%B9%88%E8%AE%A9%E6%A8%A1%E5%9E%8B%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%88%A9%E7%94%A8%E7%9F%A5%E8%AF%86%E7%94%9F%E6%88%90%E5%9B%9E%E5%A4%8D">怎么让模型更好的利用知识生成回复？</a></li>
</ul>
</li>
<li><a href="#agentic-rag">Agentic RAG</a>
<ul>
<li><a href="#agentic-rag-%E6%A0%B7%E4%BE%8B">Agentic RAG 样例</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">代码示例</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84-agentic-rag">基于强化学习的 Agentic RAG</a>
<ul>
<li><a href="#%E6%9C%80%E5%B0%8F%E5%AE%9E%E7%8E%B0%E7%A4%BA%E4%BE%8B">最小实现示例</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0">参考文章</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://voluntexi.github.io/rope-jie-xi/">
              <h3 class="post-title">
                RoPE 解析
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '5f187cc029307ed395eb',
    clientSecret: 'e99c3ac1d57961f0f19a3cd58bc611932d26cd1b',
    repo: 'voluntexi.github.io',
    owner: 'voluntexi',
    admin: ['voluntexi'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  属于 <a href="https://github.com/voluntexi" target="_blank">@威伦特</a><script async defer src="https://analytics.umami.is/script.js" data-website-id="95248820-3fb8-420e-8f5b-87e136cbc08d"></script>
  <a class="rss" href="https://voluntexi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
