<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://voluntexi.github.io/</id>
    <title>威伦特</title>
    <updated>2026-01-21T14:26:34.666Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://voluntexi.github.io/"/>
    <link rel="self" href="https://voluntexi.github.io/atom.xml"/>
    <subtitle>解码生命</subtitle>
    <logo>https://voluntexi.github.io/images/avatar.png</logo>
    <icon>https://voluntexi.github.io/favicon.ico</icon>
    <rights>All rights reserved 2026, 威伦特</rights>
    <entry>
        <title type="html"><![CDATA[HNSW]]></title>
        <id>https://voluntexi.github.io/hnsw/</id>
        <link href="https://voluntexi.github.io/hnsw/">
        </link>
        <updated>2026-01-21T12:50:32.000Z</updated>
        <summary type="html"><![CDATA[<p>在使用 RAG（Retrieval-Augmented Generation）时，我们通常需要在大量文本向量中，找到与查询最相似的若干条语句。最直观的方式是对所有向量逐一计算相似度（余弦相似度、欧氏距离等），然后进行比较。在数据规模较小时，这种方法尚可接受；但当数据量达到百万甚至更高量级时，逐一匹配将带来巨大的时间开销。</p>
]]></summary>
        <content type="html"><![CDATA[<p>在使用 RAG（Retrieval-Augmented Generation）时，我们通常需要在大量文本向量中，找到与查询最相似的若干条语句。最直观的方式是对所有向量逐一计算相似度（余弦相似度、欧氏距离等），然后进行比较。在数据规模较小时，这种方法尚可接受；但当数据量达到百万甚至更高量级时，逐一匹配将带来巨大的时间开销。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Agent 三大构建范式解析]]></title>
        <id>https://voluntexi.github.io/agent-build/</id>
        <link href="https://voluntexi.github.io/agent-build/">
        </link>
        <updated>2025-12-07T08:52:11.000Z</updated>
        <summary type="html"><![CDATA[<p>今年年初Manus引爆了Agent概念，随着越来越多的厂商开发发布自己的Agent，Agent逐渐的走进了大众的视野，今年可谓是<u>Agent元年</u>。而对于我们想要尝试构建自己的Agent，除开从Coze、Dify、星辰智能体平台等平台构建，还可以通过调用API通过提示词来进行进行构建。（微调不起了...）为了让大家更好的做出自己的Agent，本文主要讲解构建Agent 的经典三大范式：ReAct、Plan-and-Solve和Relection。</p>
]]></summary>
        <content type="html"><![CDATA[<p>今年年初Manus引爆了Agent概念，随着越来越多的厂商开发发布自己的Agent，Agent逐渐的走进了大众的视野，今年可谓是<u>Agent元年</u>。而对于我们想要尝试构建自己的Agent，除开从Coze、Dify、星辰智能体平台等平台构建，还可以通过调用API通过提示词来进行进行构建。（微调不起了...）为了让大家更好的做出自己的Agent，本文主要讲解构建Agent 的经典三大范式：ReAct、Plan-and-Solve和Relection。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAG 解析]]></title>
        <id>https://voluntexi.github.io/rag/</id>
        <link href="https://voluntexi.github.io/rag/">
        </link>
        <updated>2025-11-08T12:53:11.000Z</updated>
        <summary type="html"><![CDATA[<p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术的方法，旨在提升大模型输出的稳定性，减少幻觉现象</p>
]]></summary>
        <content type="html"><![CDATA[<p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术的方法，旨在提升大模型输出的稳定性，减少幻觉现象</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoPE 解析]]></title>
        <id>https://voluntexi.github.io/rope-jie-xi/</id>
        <link href="https://voluntexi.github.io/rope-jie-xi/">
        </link>
        <updated>2025-10-15T14:36:36.000Z</updated>
        <summary type="html"><![CDATA[<p>RoPE（旋转位置编码）是一种结合了绝对位置编码和相对位置编码的一种编码方法，出自苏剑林老师提出的RoFormer，现如今已经作为LLM结构的标配了，可见其效果强大。这篇文章就来具体解析一下，RoPE的原理和优势到底是什么。</p>
]]></summary>
        <content type="html"><![CDATA[<p>RoPE（旋转位置编码）是一种结合了绝对位置编码和相对位置编码的一种编码方法，出自苏剑林老师提出的RoFormer，现如今已经作为LLM结构的标配了，可见其效果强大。这篇文章就来具体解析一下，RoPE的原理和优势到底是什么。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[手写MOE]]></title>
        <id>https://voluntexi.github.io/shou-xie-moe/</id>
        <link href="https://voluntexi.github.io/shou-xie-moe/">
        </link>
        <updated>2025-09-11T10:28:25.000Z</updated>
        <summary type="html"><![CDATA[<p>MOE（Mixture of Experts）也就是混合专家系统，已经在LLM（Large Language Model）的结构中成为标配了。最近看到一篇手写MOE教程，所学下来，受益颇多。</p>
]]></summary>
        <content type="html"><![CDATA[<p>MOE（Mixture of Experts）也就是混合专家系统，已经在LLM（Large Language Model）的结构中成为标配了。最近看到一篇手写MOE教程，所学下来，受益颇多。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Whisper：Robust Speech Recognition via Large-Scale Weak Supervision]]></title>
        <id>https://voluntexi.github.io/whisper/</id>
        <link href="https://voluntexi.github.io/whisper/">
        </link>
        <updated>2025-08-06T12:04:17.000Z</updated>
        <summary type="html"><![CDATA[<p>最近有语音识别方言方面的需求，由于之前没有接触到过这个领域，遂深入了解一下Open AI发布的语音识别模型Whisper</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近有语音识别方言方面的需求，由于之前没有接触到过这个领域，遂深入了解一下Open AI发布的语音识别模型Whisper</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[LMCache]]></title>
        <id>https://voluntexi.github.io/lmcache/</id>
        <link href="https://voluntexi.github.io/lmcache/">
        </link>
        <updated>2025-07-19T11:16:14.000Z</updated>
        <summary type="html"><![CDATA[<p>想要大模型在通用性上获得更好的效果，就需要让大模型对更多的领域知识进行“补充”。</p>
<p>《Do Large Language Models Need a Content Delivery Network》论文提出了 KDN（Knowledge Delivery Network），简单来说就是对输入进行“缓存”，从而提升模型首个 Token 响应时间，并将 KDN 开源为 <a href="https://github.com/LMCache/LMCache"><strong>LMCache</strong></a></p>
]]></summary>
        <content type="html"><![CDATA[<p>想要大模型在通用性上获得更好的效果，就需要让大模型对更多的领域知识进行“补充”。</p>
<p>《Do Large Language Models Need a Content Delivery Network》论文提出了 KDN（Knowledge Delivery Network），简单来说就是对输入进行“缓存”，从而提升模型首个 Token 响应时间，并将 KDN 开源为 <a href="https://github.com/LMCache/LMCache"><strong>LMCache</strong></a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MCP && Function Calling]]></title>
        <id>https://voluntexi.github.io/mcp-and-function-calling/</id>
        <link href="https://voluntexi.github.io/mcp-and-function-calling/">
        </link>
        <updated>2025-05-26T05:16:18.000Z</updated>
        <summary type="html"><![CDATA[<p>Function Calling 和 MCP 通过一组外部工具，帮助 LLM 获取其<strong>无法直接知晓的信息</strong>或者<strong>难以执行的操作</strong>。本文分别对他们进行说明，并对比异同</p>
]]></summary>
        <content type="html"><![CDATA[<p>Function Calling 和 MCP 通过一组外部工具，帮助 LLM 获取其<strong>无法直接知晓的信息</strong>或者<strong>难以执行的操作</strong>。本文分别对他们进行说明，并对比异同</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[KV Cache]]></title>
        <id>https://voluntexi.github.io/kv-cache/</id>
        <link href="https://voluntexi.github.io/kv-cache/">
        </link>
        <updated>2025-03-11T06:01:00.000Z</updated>
        <summary type="html"><![CDATA[<p>KV Cache是一种针对Transformer-Decoder部分的注意力层的优化技术，其原理是通过缓存之前生成的KV值，提高模型的推理性能。</p>
]]></summary>
        <content type="html"><![CDATA[<p>KV Cache是一种针对Transformer-Decoder部分的注意力层的优化技术，其原理是通过缓存之前生成的KV值，提高模型的推理性能。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[正确使用 ORDER BY + LIMIT]]></title>
        <id>https://voluntexi.github.io/zheng-que-shi-yong-order-by-limit/</id>
        <link href="https://voluntexi.github.io/zheng-que-shi-yong-order-by-limit/">
        </link>
        <updated>2024-08-20T07:54:21.000Z</updated>
        <summary type="html"><![CDATA[<p>当我们想在分页查询中对数据进行排序展示时，通常会使用 <code>ORDER BY</code> 进行排序。然而，当用于排序的字段并非唯一时，可能会在翻页时遇到数据重复的问题，下面是对这个问题的具体分析和解决方案。</p>
]]></summary>
        <content type="html"><![CDATA[<p>当我们想在分页查询中对数据进行排序展示时，通常会使用 <code>ORDER BY</code> 进行排序。然而，当用于排序的字段并非唯一时，可能会在翻页时遇到数据重复的问题，下面是对这个问题的具体分析和解决方案。</p>
]]></content>
    </entry>
</feed>