<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>B站视频和用户评论爬虫 | 威伦特</title>
<link rel="shortcut icon" href="https://voluntexi.github.io//favicon.ico?v=1760695118645">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://voluntexi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="B站视频和用户评论爬虫 | 威伦特 - Atom Feed" href="https://voluntexi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="本文将详细的讲述关于B站网络爬虫的实现过程。

概述一下，其实B站的爬取过程就是：
对哔哩哔哩视频页面进行oid信息的提取，而oid的信息又与原网址的BV信息有关联，可以通过原网站进行解析出oid信息，然后在抖音爬虫的基础上即可完成哔哩哔哩..." />
    <meta name="keywords" content="网络爬虫" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://voluntexi.github.io/">
  <img class="avatar" src="https://voluntexi.github.io//images/avatar.png?v=1760695118645" alt="">
  </a>
  <h1 class="site-title">
    威伦特
  </h1>
  <p class="site-description">
    解码生命
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              B站视频和用户评论爬虫
            </h2>
            <div class="post-info">
              <span>
                2022-05-30
              </span>
              <span>
                10 min read
              </span>
              
                <a href="https://voluntexi.github.io/_of5dqwwh/" class="post-tag">
                  # 网络爬虫
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-8617dbabc38aaa87b878b6ee5d615f8f_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic3.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1658553842&amp;t=dcf4e4220f062ca915fedcc7b797c4c2" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <p>本文将详细的讲述关于B站网络爬虫的实现过程。</p>
<!-- more -->
<p>概述一下，其实B站的爬取过程就是：</p>
<p><strong>对哔哩哔哩视频页面进行oid信息的提取，而oid的信息又与原网址的BV信息有关联，可以通过原网站进行解析出oid信息，然后在抖音爬虫的基础上即可完成哔哩哔哩爬虫的信息提取任务。</strong></p>
 <!--more-->
<h2 id="b站网站分析">B站网站分析</h2>
<p>首先，我们找到想要抓取的对应的哔哩哔哩视频，按下F12，在开发者模式中，进行观察评论、视频等信息的存储方式。发现哔哩哔哩视频的相关信息也是通过动态显示，且通过提取请求头中的有效信息，最终请求头为：</p>
<p>https://api.bilibili.com/x/v2/reply/main?&amp;type=1&amp;oid=725453240&amp;mode=3</p>
<p>通过与哔哩哔哩网址其他视频评论进行对比，发现仅有oid参数有所不同，也就是说，每个视频下面对应有不同的oid，只需要找到视频的oid便可以实现视频相关信息的提取。<br>
<img src="https://voluntexi.github.io//post-images/1655960679008.jpg" alt="" loading="lazy"><br>
同时进一步发现，可以在请求地址后加入&amp;page就可以进行翻页操作。</p>
<p>由此，哔哩哔哩的用户评论相关信息也就成功解析出来，剩下操作需要找到视频链接和oid之间的联系，而通过视频链接进行解析出oid信息。</p>
<p>而通过对视频网址源代码的分析，发现oid存在其中，不但如此，同样在网站源代码中找到了哔哩哔哩视频的地址。<br>
<img src="https://voluntexi.github.io//post-images/1655960698023.jpg" alt="" loading="lazy"></p>
<center>源代码下的oid信息展示</center>
但此时，若直接访问该地址会出现403错误信息，经过层层分析后，发现添加了访问请求头后，便可完成视频的爬取。
<h2 id="哔哩哔哩爬虫的实现">哔哩哔哩爬虫的实现</h2>
<h3 id="构造请求头向哔哩哔哩模拟requests请求提取网站存储的用户信息">构造请求头向哔哩哔哩模拟requests请求，提取网站存储的用户信息：</h3>
<p>通过构造BilibiliCrawler函数，并通过构造形参来接受请求的URL。并通过&amp;page增加1的操作来进行翻页。</p>
<p>在使用Google Chrome浏览器访问哔哩哔哩的时候，浏览器页会向哔哩哔哩网页版的服务器自动的发送headers请求头。这时候可以在开发者模式中查看请求头，查看方式和上一文抖音爬虫中方式相同，具体标头如图所示。<br>
<img src="https://voluntexi.github.io//post-images/1655960739226.jpg" alt="" loading="lazy"><br>
Hearders的请求头如下</p>
<pre><code class="language-python">headers = {
'Accept-Encoding': 'gzip, deflate, sdch',
'Accept-Language': 'en-US,en;q=0.8',
'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',
'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
'Connection': 'keep-alive',
'cookie':&quot;填上自己的cookie&quot;
}
</code></pre>
<p>接下来就可以对网站的数据进行获取，将数据通过一个数组保存下来</p>
<pre><code class="language-python">def Html(html):
#     获取所需内容
    s=json.loads(html)
    for i in range(20):
        comment=s['data']['replies'][i]
        floor = comment['member']['mid']
        sex=comment['member']['sex']
        ctime = time.strftime(&quot;%Y-%m-%d&quot;,time.localtime(comment['ctime']))
        content = comment['content']['message']
        likes = comment['like']
        rcounts = comment['rcount']
        username=comment['member']['uname']
        content=comment['content']['message']
        list=[]
        print(floor)
        list.append(floor)
        list.append(username)
        list.append(content)
        list.append(ctime)
    com.append(list)

</code></pre>
<p>biliVideo函数来获取当前页面下的哔哩哔哩视频，通过对哔哩哔哩源代码的的解析，分析出视频的网址。下载视频的函数bliVideo函数代码如下：</p>
<pre><code class="language-python">    url=url.partition('?')[0]
    print(url)
    print('获取中')
    response = requests.get(url, headers).text
    pattern = '&lt;script&gt;window\.__playinfo__=(.*?)&lt;/script&gt;'
    list = re.findall(pattern, response, re.S)
    list_json = json.loads(list[0])
    title_pattern = '&lt;span class=&quot;tit&quot;&gt;(.*?)&lt;/span&gt;'
    try:
        title = re.findall(title_pattern, response, re.S)[0]
    except:
        title = 'B站未知视频'
    video_url = list_json['data']['dash']['video'][0]['baseUrl']
    volume_url = list_json['data']['dash']['audio'][0]['baseUrl']
    print(title[0:6] + '获取成功，准备下载')
    video_headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36 Edg/91.0.864.37',
        'cookie': ''
    }
    video_param = {
        'accept_description': '360P 流畅',
        'accept_quality': 60,
    }
    print(&quot;视频url：&quot;+video_url)
    print('-----开始下载-----')
    video = requests.get(url=video_url, headers=video_headers, params=video_param).content
    # with open('../video/'+r'.\B站{}.mp4'.format(title), 'wb') as f:
    with open('../video/BVideo.mp4', 'wb') as f:
        f.write(video)
</code></pre>
<p>值得注意的是，哔哩哔哩相对于爬虫的环境相对较为轻松，但是其中在抓取数据的时候不要太快、太频繁，通过time.sleep()来进行暂停，防止被反爬虫程序所识别而封掉IP。</p>
<h2 id="完整代码">完整代码</h2>
<pre><code class="language-python">import time
import xlwt
import requests
import re
import json
'''
功能：爬取B站ID、用户名、用户评论
使用方法：
在def BilibiliCrawler(Old_url)函数中 输入爬取的网站链接 即可实现信息的爬取和视频的下载，下载路径为video/Bvideo.mp4
在爬取完毕后会将数据以EXCEL表的形式存入当前目录，命名为：BilibiliComment.xls
'''
com=[]
def require(url):
    headers = {
        'Accept-Encoding': 'gzip, deflate, sdch',
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/39.0.2171.95 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'cookie': &quot;&quot;
    }
    try:
        r=requests.get(url,headers=headers)
        r.raise_for_status()
        print(url)
        return r.text
    except requests.HTTPError as e:
        print(e)
    except requests.RequestException as e:
        print(e)
    except:
        print(&quot;Unknow error&quot;)
def Html(html):
#     获取所需内容
    s=json.loads(html)
    for i in range(20):
        comment=s['data']['replies'][i]
        floor = comment['member']['mid']
        sex=comment['member']['sex']
        ctime = time.strftime(&quot;%Y-%m-%d&quot;,time.localtime(comment['ctime']))
        content = comment['content']['message']
        likes = comment['like']
        rcounts = comment['rcount']
        username=comment['member']['uname']
        content=comment['content']['message']
        list=[]
        print(floor)
        list.append(floor)
        list.append(username)
        list.append(content)
        list.append(ctime)
        com.append(list)
def save_afile(alls,filename):
    &quot;&quot;&quot;将一个评论数据保存在一个excle&quot;&quot;&quot;
    f=xlwt.Workbook()
    sheet1=f.add_sheet(u'sheet1',cell_overwrite_ok=True)
    sheet1.write(0,0,'Comment_ID')
    sheet1.write(0,1,'Comment_Name')
    sheet1.write(0,2,'Comment_Content')
    sheet1.write(0,3,'Comment_Time')
    i=1
    for data in alls:
        for j in range(len(data)):
            sheet1.write(i,j,data[j])
            # print(i,j,data[j])
        i=i+1
    f.save(filename+'.xls')
def biliVideo(url):
    headers = {
        'Referer': 'https://www.bilibili.com/video/BV1bK4y19743?spm_id_from=333.5.b_64616e63655f6f74616b75.8',
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'
    }
    url=url.partition('?')[0]
    print(url)
    print('获取中')
    response = requests.get(url, headers).text
    pattern = '&lt;script&gt;window\.__playinfo__=(.*?)&lt;/script&gt;'
    list = re.findall(pattern, response, re.S)
    list_json = json.loads(list[0])
    title_pattern = '&lt;span class=&quot;tit&quot;&gt;(.*?)&lt;/span&gt;'
    try:
        title = re.findall(title_pattern, response, re.S)[0]
    except:
        title = 'B站未知视频'
    video_url = list_json['data']['dash']['video'][0]['baseUrl']
    volume_url = list_json['data']['dash']['audio'][0]['baseUrl']
    print(title[0:6] + '获取成功，准备下载')
    video_headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36 Edg/91.0.864.37',
        'cookie': &quot;“
    }
    video_param = {
        'accept_description': '360P 流畅',
        'accept_quality': 60,
    }
    print(&quot;视频url：&quot;+video_url)
    print('-----开始下载-----')
    video = requests.get(url=video_url, headers=video_headers, params=video_param).content
    # with open('../video/'+r'.\B站{}.mp4'.format(title), 'wb') as f:
    with open('../video/BVideo.mp4', 'wb') as f:
        f.write(video)
    #     print('视频下载中')
    # audio = requests.get(url=volume_url, headers=video_headers).content
    # with open('./audio.mp3', 'wb') as f:
    #     f.write(audio)
    # print('-----视频合成中-----')
    # print('-----请耐心等候-----')
    # video_path = './B站视频.mp4'
    # videoclip = VideoFileClip(video_path)
    # audio_path = './audio.mp3'
    # audio = AudioFileClip(audio_path)
    # videoclip_3 = videoclip.set_audio(audio)
    # path = r'.\B站{}.mp4'.format(title[0:6])
    # videoclip_3.write_videofile(path)
    # import os
    # if os.path.exists(video_path):
    #     os.remove(video_path)
    # else:
    #     pass
    # if os.path.exists(audio_path):
    #     os.remove(audio_path)
    #     print('success!!!')
    # else:
    #     pass
    return title
def getOid(url):
    bv = re.findall('https://www.bilibili.com/video/(.*?)\?', url, re.S)[0]
    print(bv)
    resp = requests.get(&quot;https://www.bilibili.com/video/&quot; + bv)
    obj = re.compile(f'&quot;aid&quot;:(?P&lt;id&gt;.*?),&quot;bvid&quot;:&quot;{bv}&quot;')  # 在网页源代码里可以找到id，用正则获取到
    oid = obj.search(resp.text).group('id')
    return oid
def BilibiliCrawler(url):
    videoName=biliVideo(url)
    oid=getOid(url)
    print(oid)
    Old_url = 'https://api.bilibili.com/x/v2/reply?type=1&amp;sort=1&amp;oid=' + str(oid) + '&amp;pn='
    e=0
    page=1
    while e == 0 :
        url = Old_url+str(page)
        try:
            html=require(url)
            Html(html)
            page=page+1
            if page%10 == 0:
                time.sleep(3)
            if page&gt;30:
                break
        except:
            e=1
    save_afile(com,&quot;bilibili_comment&quot;)
    return videoName

</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#b%E7%AB%99%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90">B站网站分析</a></li>
<li><a href="#%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E7%88%AC%E8%99%AB%E7%9A%84%E5%AE%9E%E7%8E%B0">哔哩哔哩爬虫的实现</a>
<ul>
<li><a href="#%E6%9E%84%E9%80%A0%E8%AF%B7%E6%B1%82%E5%A4%B4%E5%90%91%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E6%A8%A1%E6%8B%9Frequests%E8%AF%B7%E6%B1%82%E6%8F%90%E5%8F%96%E7%BD%91%E7%AB%99%E5%AD%98%E5%82%A8%E7%9A%84%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF">构造请求头向哔哩哔哩模拟requests请求，提取网站存储的用户信息：</a></li>
</ul>
</li>
<li><a href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">完整代码</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://voluntexi.github.io/dou-yin-shi-pin-he-yong-hu-ping-lun-pa-chong/">
              <h3 class="post-title">
                抖音视频和用户评论爬虫
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '5f187cc029307ed395eb',
    clientSecret: 'e99c3ac1d57961f0f19a3cd58bc611932d26cd1b',
    repo: 'voluntexi.github.io',
    owner: 'voluntexi',
    admin: ['voluntexi'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  属于 <a href="https://github.com/voluntexi" target="_blank">@威伦特</a><script async defer src="https://analytics.umami.is/script.js" data-website-id="95248820-3fb8-420e-8f5b-87e136cbc08d"></script>
  <a class="rss" href="https://voluntexi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
