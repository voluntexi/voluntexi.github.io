<html>
  <head>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>NLP | 威伦特</title>
<link rel="shortcut icon" href="https://voluntexi.github.io//favicon.ico?v=1760695118645">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://voluntexi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="NLP | 威伦特 - Atom Feed" href="https://voluntexi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



  <meta name="description" content=" Welcome to my Blog and it's my intention it will breed knowledge. " />
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://voluntexi.github.io/">
  <img class="avatar" src="https://voluntexi.github.io//images/avatar.png?v=1760695118645" alt="">
  </a>
  <h1 class="site-title">
    威伦特
  </h1>
  <p class="site-description">
    解码生命
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="current-tag-container">
            <h2 class="title">
                标签：# NLP
            </h2> 
        </div>
        <div class="post-container">
  
    <article class="post">
      <a href="https://voluntexi.github.io/rope-jie-xi/">
        <h2 class="post-title">RoPE 解析</h2>
      </a>
      <div class="post-info">
        <span>
          2025-10-15
        </span>
        <span>
          21 min read
        </span>
        
          <a href="https://voluntexi.github.io/da-mo-xing/" class="post-tag">
            # 大模型
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/rope-jie-xi/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/rope-jie-xi.png')">
        </a>
      
      <div class="post-abstract">
        <p>RoPE（旋转位置编码）是一种结合了绝对位置编码和相对位置编码的一种编码方法，出自苏剑林老师提出的RoFormer，现如今已经作为LLM结构的标配了，可见其效果强大。这篇文章就来具体解析一下，RoPE的原理和优势到底是什么。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/shou-xie-moe/">
        <h2 class="post-title">手写MOE</h2>
      </a>
      <div class="post-info">
        <span>
          2025-09-11
        </span>
        <span>
          10 min read
        </span>
        
          <a href="https://voluntexi.github.io/da-mo-xing/" class="post-tag">
            # 大模型
          </a>
        
          <a href="https://voluntexi.github.io/dai-ma/" class="post-tag">
            # 代码
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/shou-xie-moe/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/shou-xie-moe.png')">
        </a>
      
      <div class="post-abstract">
        <p>MOE（Mixture of Experts）也就是混合专家系统，已经在LLM（Large Language Model）的结构中成为标配了。最近看到一篇手写MOE教程，所学下来，受益颇多。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/lmcache/">
        <h2 class="post-title">LMCache</h2>
      </a>
      <div class="post-info">
        <span>
          2025-07-19
        </span>
        <span>
          11 min read
        </span>
        
          <a href="https://voluntexi.github.io/da-mo-xing/" class="post-tag">
            # 大模型
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/lmcache/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/lmcache.png')">
        </a>
      
      <div class="post-abstract">
        <p>想要大模型在通用性上获得更好的效果，就需要让大模型对更多的领域知识进行“补充”。</p>
<p>《Do Large Language Models Need a Content Delivery Network》论文提出了 KDN（Knowledge Delivery Network），简单来说就是对输入进行“缓存”，从而提升模型首个 Token 响应时间，并将 KDN 开源为 <strong>LMCache</strong>（https://github.com/LMCache/LMCache）</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/mcp-and-function-calling/">
        <h2 class="post-title">MCP &amp;&amp; Function Calling</h2>
      </a>
      <div class="post-info">
        <span>
          2025-05-26
        </span>
        <span>
          8 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/mcp-and-function-calling/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/mcp-and-function-calling.png')">
        </a>
      
      <div class="post-abstract">
        <p>Function Calling 和 MCP 通过一组外部工具，帮助 LLM 获取其<strong>无法直接知晓的信息</strong>或者<strong>难以执行的操作</strong>。本文分别对他们进行说明，并对比异同</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/kv-cache/">
        <h2 class="post-title">KV Cache</h2>
      </a>
      <div class="post-info">
        <span>
          2025-03-11
        </span>
        <span>
          11 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/kv-cache/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/kv-cache.jpg')">
        </a>
      
      <div class="post-abstract">
        <p>KV Cache是一种针对Transformer-Decoder部分的注意力层的优化技术，其原理是通过缓存之前生成的KV值，提高模型的推理性能。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/prompt-learning/">
        <h2 class="post-title">Prompt Learning</h2>
      </a>
      <div class="post-info">
        <span>
          2023-12-12
        </span>
        <span>
          9 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/prompt-learning/" class="post-feature-image" style="background-image: url('https://miro.medium.com/v2/resize:fit:1100/format:webp/0*gJlUvCo-c1r0vbtz.png')">
        </a>
      
      <div class="post-abstract">
        <p><strong>Prompt Learning 的本质就是将所有下游任务统一成预训练任务；</strong> 以特定的模板，将下游任务的数据转成自然语言形式，从而充分挖掘预训练语言模型本身的能力。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/less-is-more/">
        <h2 class="post-title">Less is More for Long Document Summary Evaluation by LLMs</h2>
      </a>
      <div class="post-info">
        <span>
          2023-10-09
        </span>
        <span>
          4 min read
        </span>
        
          <a href="https://voluntexi.github.io/wen-ben-zhai-yao/" class="post-tag">
            # 文本摘要
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/less-is-more/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/less-is-more.png')">
        </a>
      
      <div class="post-abstract">
        <p>这篇文章给了我们一种如何在自己研究的领域去&quot;蹭&quot;大模型热度的思路</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/PGA/">
        <h2 class="post-title">Generating EDU Extracts for Plan-Guided Summary Re-Ranking</h2>
      </a>
      <div class="post-info">
        <span>
          2023-09-09
        </span>
        <span>
          7 min read
        </span>
        
          <a href="https://voluntexi.github.io/wen-ben-zhai-yao/" class="post-tag">
            # 文本摘要
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/PGA/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/PGA.png')">
        </a>
      
      <div class="post-abstract">
        <p>这篇文章是在我之前介绍的<strong>BRIO模型（<a href="https://voluntexi.github.io/brio/">BRIO | 威伦特 (voluntexi.github.io)</a>）<strong>的基础上改进的，模型的整体框架也是采用两步式摘要，即结合</strong>生成候选摘要</strong>和<strong>评估候选摘要</strong>两个阶段来获得最佳摘要。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/copy-is-all-you-need/">
        <h2 class="post-title">Copy is All You Need</h2>
      </a>
      <div class="post-info">
        <span>
          2023-08-21
        </span>
        <span>
          13 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/copy-is-all-you-need/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/copy-is-all-you-need.png')">
        </a>
      
      <div class="post-abstract">
        <p>最近在<a href="https://paperswithcode.com/">paper with code</a>刷论文的时候，看到了一个很唬人的文章“《Copy is All You Need》”，遂找来研读研读，发现内容还是很有意思，准备写一篇阅读笔记的，偶然发现了这篇文章作者的采访稿，将文章背后的故事都介绍的挺详细的。于是乎转载一下（不是偷懒）</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/longnet/">
        <h2 class="post-title"> LONGNET: Scaling Transformers to 1,000,000,000 Tokens</h2>
      </a>
      <div class="post-info">
        <span>
          2023-07-21
        </span>
        <span>
          5 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/longnet/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/longnet.png')">
        </a>
      
      <div class="post-abstract">
        <p>前段时间刚介绍了能使模型处理上下文扩展到百万级别的方法，现在微软又提出了一种能扩展到十亿级别的方法（不过有标题党的嫌疑，因为在实验中作者只扩展到了百万级别）</p>

      </div>
    </article>
  
</div>

        <div class="pagination-container">
  
  
    <a href="https://voluntexi.github.io/Non44iZPB/page/2" class="next-page">下一页</a>
  
</div>

        <div class="site-footer">
  属于 <a href="https://github.com/voluntexi" target="_blank">@威伦特</a><script async defer src="https://analytics.umami.is/script.js" data-website-id="95248820-3fb8-420e-8f5b-87e136cbc08d"></script>
  <a class="rss" href="https://voluntexi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>
  </body>
</html>
