<html>
  <head>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>NLP | 威伦特</title>
<link rel="shortcut icon" href="https://voluntexi.github.io//favicon.ico?v=1769005591865">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://voluntexi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="NLP | 威伦特 - Atom Feed" href="https://voluntexi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



  <meta name="description" content=" Welcome to my Blog and it's my intention it will breed knowledge. " />
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://voluntexi.github.io/">
  <img class="avatar" src="https://voluntexi.github.io//images/avatar.png?v=1769005591865" alt="">
  </a>
  <h1 class="site-title">
    威伦特
  </h1>
  <p class="site-description">
    解码生命
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="current-tag-container">
            <h2 class="title">
                标签：# NLP
            </h2> 
        </div>
        <div class="post-container">
  
    <article class="post">
      <a href="https://voluntexi.github.io/longnet/">
        <h2 class="post-title"> LONGNET: Scaling Transformers to 1,000,000,000 Tokens</h2>
      </a>
      <div class="post-info">
        <span>
          2023-07-21
        </span>
        <span>
          5 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/longnet/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/longnet.png')">
        </a>
      
      <div class="post-abstract">
        <p>前段时间刚介绍了能使模型处理上下文扩展到百万级别的方法，现在微软又提出了一种能扩展到十亿级别的方法（不过有标题党的嫌疑，因为在实验中作者只扩展到了百万级别）</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/scalingTo1m/">
        <h2 class="post-title">Scaling Transformer to 1M tokens and beyond with RMT</h2>
      </a>
      <div class="post-info">
        <span>
          2023-07-07
        </span>
        <span>
          6 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/scalingTo1m/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/scalingTo1m.png')">
        </a>
      
      <div class="post-abstract">
        <p>当我还在用最大一次只能处理1024个上下文的BART模型做实验时，已经有能处理上百万上下文的方法了🤡</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/lora/">
        <h2 class="post-title">LoRA</h2>
      </a>
      <div class="post-info">
        <span>
          2023-06-04
        </span>
        <span>
          10 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/lora/" class="post-feature-image" style="background-image: url('https://p8.itc.cn/q_70/images03/20220319/d6bfb1e2afe6495a9252d2d545009dc6.png')">
        </a>
      
      <div class="post-abstract">
        <p>在如今大模型时代，如果需要微调一个大模型无疑在时间和金钱方面的消耗是巨大的，而LoRA通过冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到Transformer架构的每一层中，大大减少了下游任务的可训练参数的数量。尽管LoRA使得可训练参数更少，但是与微调效果相比结果相当甚至更好。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/longformer/">
        <h2 class="post-title">Longformer</h2>
      </a>
      <div class="post-info">
        <span>
          2023-05-18
        </span>
        <span>
          6 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/longformer/" class="post-feature-image" style="background-image: url('https://pic4.zhimg.com/v2-f903a672ed4c3e0b41ec4ee89a2c8060_1440w.jpg?source=172ae18b')">
        </a>
      
      <div class="post-abstract">
        <p>Longformer是一种用来拓展模型在长序列建模的能力算法，它提出了一种时空复杂度同文本序列长度呈线性关系的Self-Attention，用以保证能够使得模型高效处理长文本。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/SimCSE/">
        <h2 class="post-title">SimCSE</h2>
      </a>
      <div class="post-info">
        <span>
          2023-04-27
        </span>
        <span>
          6 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/SimCSE/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/SimCSE.png')">
        </a>
      
      <div class="post-abstract">
        <p>最近做实验需要用到Sentence  Embeddings（句向量），特地研究了一下句向量相关模型算法，其中 SimCSE 模型是目前比较火、效果也比较好的一个模型。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/Survey2/">
        <h2 class="post-title"> An Empirical Survey on Long Document Summarization,Part 2：Model</h2>
      </a>
      <div class="post-info">
        <span>
          2023-04-15
        </span>
        <span>
          16 min read
        </span>
        
          <a href="https://voluntexi.github.io/wen-ben-zhai-yao/" class="post-tag">
            # 文本摘要
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/Survey2/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/Survey2.png')">
        </a>
      
      <div class="post-abstract">
        <p>本文是论文《An Empirical Survey on Long Document Summarization》的阅读笔记第二部分，介绍了抽取式、生成式和混合式三种长文本摘要方法及其对应有哪些代表模型。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/Survey1/">
        <h2 class="post-title">An Empirical Survey on Long Document Summarization,Part 1：Introduction and Datasets</h2>
      </a>
      <div class="post-info">
        <span>
          2023-04-12
        </span>
        <span>
          8 min read
        </span>
        
          <a href="https://voluntexi.github.io/wen-ben-zhai-yao/" class="post-tag">
            # 文本摘要
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/Survey1/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/Survey1.png')">
        </a>
      
      <div class="post-abstract">
        <p>论文《An Empirical Survey on Long Document Summarization》对长文本摘要领域通过模型、数据集和评价指标三个方面进行了全面的概述，文本是该论文阅读笔记第一部分，描述了长文本的概念，介绍了目前的数据集。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/dui-yu-xun-lian-mo-xing-jin-xing-wei-diao/">
        <h2 class="post-title">对预训练模型进行微调</h2>
      </a>
      <div class="post-info">
        <span>
          2023-03-01
        </span>
        <span>
          7 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/dui-yu-xun-lian-mo-xing-jin-xing-wei-diao/" class="post-feature-image" style="background-image: url('https://img1.baidu.com/it/u=1732097677,3720483819&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=PNG?w=500&amp;h=208')">
        </a>
      
      <div class="post-abstract">
        <p>​	近年来随着自然语言处理技术的不断发展，预训练模型已经成为了近年来最热门的研究方向之一。预训练模型有更好的性能表现。然而，对于刚接触的人来说，阵对预训练模型的训练可能会显得复杂和难以理解。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/moca/">
        <h2 class="post-title">MoCa</h2>
      </a>
      <div class="post-info">
        <span>
          2023-02-22
        </span>
        <span>
          7 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/moca/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/moca.jpg')">
        </a>
      
      <div class="post-abstract">
        <p>BRIO在生成式文本摘要领域SOTA位置还没坐稳几个月，便出现了新的SOTA—MoCa</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/brio/">
        <h2 class="post-title">BRIO</h2>
      </a>
      <div class="post-info">
        <span>
          2023-02-08
        </span>
        <span>
          9 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/brio/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/brio.png')">
        </a>
      
      <div class="post-abstract">
        <p>BRIO是2022年文本摘要领域SOTA，通过结合了对比学习解决了生成式摘要领域seq2seq自回归中的exposure bias问题</p>

      </div>
    </article>
  
</div>

        <div class="pagination-container">
  
    <a href="https://voluntexi.github.io/Non44iZPB" class="prev-page">上一页</a>
  
  
    <a href="https://voluntexi.github.io/Non44iZPB/page/3/" class="next-page">下一页</a>
  
</div>

        <div class="site-footer">
  属于 <a href="https://github.com/voluntexi" target="_blank">@威伦特</a><script async defer src="https://analytics.umami.is/script.js" data-website-id="95248820-3fb8-420e-8f5b-87e136cbc08d"></script>
  <a class="rss" href="https://voluntexi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>
  </body>
</html>
