<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>威伦特</title>
<link rel="shortcut icon" href="https://voluntexi.github.io//favicon.ico?v=1769005591865">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://voluntexi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="威伦特 - Atom Feed" href="https://voluntexi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content=" Welcome to my Blog and it's my intention it will breed knowledge. " />
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://voluntexi.github.io/">
  <img class="avatar" src="https://voluntexi.github.io//images/avatar.png?v=1769005591865" alt="">
  </a>
  <h1 class="site-title">
    威伦特
  </h1>
  <p class="site-description">
    解码生命
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

    
        <div class="post-container">
  
    <article class="post">
      <a href="https://voluntexi.github.io/Survey1/">
        <h2 class="post-title">An Empirical Survey on Long Document Summarization,Part 1：Introduction and Datasets</h2>
      </a>
      <div class="post-info">
        <span>
          2023-04-12
        </span>
        <span>
          8 min read
        </span>
        
          <a href="https://voluntexi.github.io/wen-ben-zhai-yao/" class="post-tag">
            # 文本摘要
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/Survey1/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/Survey1.png')">
        </a>
      
      <div class="post-abstract">
        <p>论文《An Empirical Survey on Long Document Summarization》对长文本摘要领域通过模型、数据集和评价指标三个方面进行了全面的概述，文本是该论文阅读笔记第一部分，描述了长文本的概念，介绍了目前的数据集。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/dui-yu-xun-lian-mo-xing-jin-xing-wei-diao/">
        <h2 class="post-title">对预训练模型进行微调</h2>
      </a>
      <div class="post-info">
        <span>
          2023-03-01
        </span>
        <span>
          7 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/dui-yu-xun-lian-mo-xing-jin-xing-wei-diao/" class="post-feature-image" style="background-image: url('https://img1.baidu.com/it/u=1732097677,3720483819&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=PNG?w=500&amp;h=208')">
        </a>
      
      <div class="post-abstract">
        <p>​	近年来随着自然语言处理技术的不断发展，预训练模型已经成为了近年来最热门的研究方向之一。预训练模型有更好的性能表现。然而，对于刚接触的人来说，阵对预训练模型的训练可能会显得复杂和难以理解。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/moca/">
        <h2 class="post-title">MoCa</h2>
      </a>
      <div class="post-info">
        <span>
          2023-02-22
        </span>
        <span>
          7 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/moca/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/moca.jpg')">
        </a>
      
      <div class="post-abstract">
        <p>BRIO在生成式文本摘要领域SOTA位置还没坐稳几个月，便出现了新的SOTA—MoCa</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/brio/">
        <h2 class="post-title">BRIO</h2>
      </a>
      <div class="post-info">
        <span>
          2023-02-08
        </span>
        <span>
          9 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/brio/" class="post-feature-image" style="background-image: url('https://voluntexi.github.io//post-images/brio.png')">
        </a>
      
      <div class="post-abstract">
        <p>BRIO是2022年文本摘要领域SOTA，通过结合了对比学习解决了生成式摘要领域seq2seq自回归中的exposure bias问题</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/bert/">
        <h2 class="post-title">BERT</h2>
      </a>
      <div class="post-info">
        <span>
          2022-12-28
        </span>
        <span>
          6 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/bert/" class="post-feature-image" style="background-image: url('https://img1.baidu.com/it/u=2880138106,1379969921&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=640&amp;h=324')">
        </a>
      
      <div class="post-abstract">
        <p><strong>BERT</strong>(Bidirectional Encoder Representation from Transformers)，BERT模型在结构上简单来讲就是一个多层的transformer的<strong>Encoder</strong></p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/transformer/">
        <h2 class="post-title">Transformer</h2>
      </a>
      <div class="post-info">
        <span>
          2022-12-01
        </span>
        <span>
          13 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/transformer/" class="post-feature-image" style="background-image: url('https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg-blog.csdnimg.cn%2F20210307173356317.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NjEwOTE1%2Csize_16%2Ccolor_FFFFFF%2Ct_70&amp;refer=http%3A%2F%2Fimg-blog.csdnimg.cn&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1670754998&amp;t=7f66b9c8cf8c12113138065d2aa0ff0e')">
        </a>
      
      <div class="post-abstract">
        <p>Transformer 是 Google 的团队在 2017 年提出的一种 NLP 经典模型，现在比较火热的 Bert 也是基于 Transformer。Transformer 模型使用了 Self-Attention 机制，不采用 RNN 的顺序结构，使得模型可以并行化训练，而且能够拥有全局信息。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/cnn/">
        <h2 class="post-title">CNN</h2>
      </a>
      <div class="post-info">
        <span>
          2022-11-25
        </span>
        <span>
          12 min read
        </span>
        
          <a href="https://voluntexi.github.io/snv-Knj4H/" class="post-tag">
            # 深度学习
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/cnn/" class="post-feature-image" style="background-image: url('https://img0.baidu.com/it/u=480525687,3837767930&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=GIF?w=700&amp;h=350')">
        </a>
      
      <div class="post-abstract">
        <p>卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/rnn/">
        <h2 class="post-title">RNN</h2>
      </a>
      <div class="post-info">
        <span>
          2022-11-18
        </span>
        <span>
          13 min read
        </span>
        
          <a href="https://voluntexi.github.io/snv-Knj4H/" class="post-tag">
            # 深度学习
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/rnn/" class="post-feature-image" style="background-image: url('https://victorzhou.com/media/rnn-post/many-to-one.svg')">
        </a>
      
      <div class="post-abstract">
        <p>递归神经网络（Recurrent Neural Network, RNN）是一种专门处理<strong>序列的</strong>神经网络。它们通常用于自然语言处理(NLP） 任务，因为RNN在处理文本方面非常有效。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/glove/">
        <h2 class="post-title">GloVe</h2>
      </a>
      <div class="post-info">
        <span>
          2022-11-04
        </span>
        <span>
          8 min read
        </span>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/glove/" class="post-feature-image" style="background-image: url('https://img2.baidu.com/it/u=3200905202,1722155058&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=PNG?w=612&amp;h=404')">
        </a>
      
      <div class="post-abstract">
        <p>GloVe(Global Vectors)是常见的词向量表示方法，GloVe模型认为语料库中单词出现的统计是学习词向量表示的无监督学习算法的重要因素。相较于word2vec，GloVe利用语料库的全局信息。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://voluntexi.github.io/fasttext/">
        <h2 class="post-title">FastText</h2>
      </a>
      <div class="post-info">
        <span>
          2022-10-29
        </span>
        <span>
          10 min read
        </span>
        
          <a href="https://voluntexi.github.io/snv-Knj4H/" class="post-tag">
            # 深度学习
          </a>
        
          <a href="https://voluntexi.github.io/Non44iZPB/" class="post-tag">
            # NLP
          </a>
        
      </div>
      
        <a href="https://voluntexi.github.io/fasttext/" class="post-feature-image" style="background-image: url('https://img1.baidu.com/it/u=56699197,1185385684&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=PNG?w=952&amp;h=500')">
        </a>
      
      <div class="post-abstract">
        <p>FastText是在word2vec的cbow和skip-gram基础上得到模型，其最大的特点是模型简洁，训练速度快且文本分类准确率也令人满意</p>

      </div>
    </article>
  
</div>

    
        <div class="pagination-container">
  
    <a href="https://voluntexi.github.io/page/2/" class="prev-page">上一页</a>
  
  
    <a href="https://voluntexi.github.io/page/4/" class="next-page">下一页</a>
  
</div>

    
        <div class="site-footer">
  属于 <a href="https://github.com/voluntexi" target="_blank">@威伦特</a><script async defer src="https://analytics.umami.is/script.js" data-website-id="95248820-3fb8-420e-8f5b-87e136cbc08d"></script>
  <a class="rss" href="https://voluntexi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>
  </body>
</html>
